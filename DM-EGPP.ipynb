{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05271c7a-7728-46ae-89f3-345891127655",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, explained_variance_score\n",
    "from sklearn.feature_selection import RFE\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ========== Loss Monitoring Functions ========== #\n",
    "def calculate_loss_metrics(y_true, y_pred):\n",
    "    \"\"\"Calculate various loss metrics for monitoring\"\"\"\n",
    "    losses = {}\n",
    "    \n",
    "    # Basic losses\n",
    "    losses['mse'] = mean_squared_error(y_true, y_pred)\n",
    "    losses['rmse'] = np.sqrt(losses['mse'])\n",
    "    losses['mae'] = mean_absolute_error(y_true, y_pred)\n",
    "    losses['mape'] = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-8))) * 100\n",
    "    \n",
    "    # Huber loss (robust to outliers)\n",
    "    delta = 1.0\n",
    "    residual = y_true - y_pred\n",
    "    losses['huber'] = np.mean(np.where(np.abs(residual) <= delta,\n",
    "                                      0.5 * residual**2,\n",
    "                                      delta * (np.abs(residual) - 0.5 * delta)))\n",
    "    \n",
    "    # Log loss (suitable for non-negative predictions)\n",
    "    losses['log_loss'] = np.mean((np.log(y_pred + 1) - np.log(y_true + 1))**2)\n",
    "    \n",
    "    return losses\n",
    "\n",
    "def calculate_comprehensive_metrics(y_true, y_pred):\n",
    "    \"\"\"Calculate comprehensive evaluation metrics\"\"\"\n",
    "    # Basic metrics\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    evs = explained_variance_score(y_true, y_pred)\n",
    "    \n",
    "    # SMAPE (Symmetric Mean Absolute Percentage Error)\n",
    "    def smape(y_true, y_pred):\n",
    "        numerator = np.abs(y_pred - y_true)\n",
    "        denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "        mask = denominator != 0\n",
    "        smape_values = np.zeros_like(numerator)\n",
    "        smape_values[mask] = (numerator[mask] / denominator[mask]) * 100\n",
    "        return np.mean(smape_values)\n",
    "    \n",
    "    smape_score = smape(y_true, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'mse': mse,\n",
    "        'mae': mae,\n",
    "        'rmse': rmse,\n",
    "        'r2': r2,\n",
    "        'evs': evs,\n",
    "        'smape': smape_score\n",
    "    }\n",
    "\n",
    "# ========== Hyperparameter Optimization with Loss Monitoring ========== #\n",
    "def fine_tune_xgb_hyperparams(X_train, y_train, X_val, y_val):\n",
    "    \"\"\"XGBoost hyperparameter fine-tuning with loss monitoring\"\"\"\n",
    "    print(\"Starting XGBoost hyperparameter optimization...\")\n",
    "    \n",
    "    param_grid = {\n",
    "        'n_estimators': [90, 95, 100, 105, 110, 115],\n",
    "        'max_depth': [5, 6, 7, 8],\n",
    "        'learning_rate': [0.08, 0.09, 0.1, 0.11, 0.12]\n",
    "    }\n",
    "    \n",
    "    best_score = -999\n",
    "    best_params = None\n",
    "    best_losses = None\n",
    "    search_count = 0\n",
    "    max_search = 50\n",
    "    all_search_losses = []\n",
    "    \n",
    "    for n_est in param_grid['n_estimators']:\n",
    "        for max_d in param_grid['max_depth']:\n",
    "            for lr in param_grid['learning_rate']:\n",
    "                if search_count >= max_search:\n",
    "                    break\n",
    "                    \n",
    "                model = xgb.XGBRegressor(\n",
    "                    n_estimators=n_est,\n",
    "                    max_depth=max_d,\n",
    "                    learning_rate=lr,\n",
    "                    subsample=0.8,\n",
    "                    colsample_bytree=0.8,\n",
    "                    reg_alpha=0.1,\n",
    "                    reg_lambda=0.1,\n",
    "                    random_state=42,\n",
    "                    verbosity=0\n",
    "                )\n",
    "                \n",
    "                # Train model\n",
    "                model.fit(X_train, y_train)\n",
    "                \n",
    "                # Predict\n",
    "                pred_train = model.predict(X_train)\n",
    "                pred_val = model.predict(X_val)\n",
    "                \n",
    "                # Calculate various losses\n",
    "                train_losses = calculate_loss_metrics(y_train, pred_train)\n",
    "                val_losses = calculate_loss_metrics(y_val, pred_val)\n",
    "                \n",
    "                # R2 as main evaluation metric\n",
    "                score = r2_score(y_val, pred_val)\n",
    "                \n",
    "                # Record search process\n",
    "                search_info = {\n",
    "                    'params': {\n",
    "                        'n_estimators': n_est,\n",
    "                        'max_depth': max_d,\n",
    "                        'learning_rate': lr\n",
    "                    },\n",
    "                    'r2_score': score,\n",
    "                    'train_losses': train_losses,\n",
    "                    'val_losses': val_losses\n",
    "                }\n",
    "                all_search_losses.append(search_info)\n",
    "                \n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_params = {\n",
    "                        'n_estimators': n_est,\n",
    "                        'max_depth': max_d,\n",
    "                        'learning_rate': lr,\n",
    "                        'subsample': 0.8,\n",
    "                        'colsample_bytree': 0.8,\n",
    "                        'reg_alpha': 0.1,\n",
    "                        'reg_lambda': 0.1\n",
    "                    }\n",
    "                    best_losses = {\n",
    "                        'train': train_losses,\n",
    "                        'val': val_losses\n",
    "                    }\n",
    "                \n",
    "                # Print progress every 10 searches\n",
    "                if (search_count + 1) % 10 == 0:\n",
    "                    print(f\"Search progress: {search_count + 1}/{max_search}, Current best R2: {best_score:.4f}\")\n",
    "                \n",
    "                search_count += 1\n",
    "    \n",
    "    print(f\"XGB best parameters: {best_params}\")\n",
    "    print(f\"XGB best score: {best_score:.4f}\")\n",
    "    \n",
    "    # Print detailed loss information\n",
    "    print(f\"XGB Best Model Loss Analysis:\")\n",
    "    print(f\"Training - MSE: {best_losses['train']['mse']:.4f}, RMSE: {best_losses['train']['rmse']:.4f}, MAE: {best_losses['train']['mae']:.4f}\")\n",
    "    print(f\"Validation - MSE: {best_losses['val']['mse']:.4f}, RMSE: {best_losses['val']['rmse']:.4f}, MAE: {best_losses['val']['mae']:.4f}\")\n",
    "    print(f\"Overfitting check - RMSE difference: {best_losses['val']['rmse'] - best_losses['train']['rmse']:+.4f}\")\n",
    "    \n",
    "    return best_params, best_losses, all_search_losses\n",
    "\n",
    "def fine_tune_lgb_hyperparams(X_train, y_train, X_val, y_val):\n",
    "    print(\"Starting LightGBM hyperparameter optimization...\")\n",
    "    \n",
    "    param_combinations = [\n",
    "        {'n_estimators': 90, 'max_depth': 5, 'learning_rate': 0.09},\n",
    "        {'n_estimators': 95, 'max_depth': 6, 'learning_rate': 0.1},\n",
    "        {'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.1},\n",
    "        {'n_estimators': 105, 'max_depth': 6, 'learning_rate': 0.11},\n",
    "        {'n_estimators': 110, 'max_depth': 7, 'learning_rate': 0.1},\n",
    "        {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.12},\n",
    "    ]\n",
    "    \n",
    "    best_score = -999\n",
    "    best_params = None\n",
    "    best_losses = None\n",
    "    all_lgb_losses = []\n",
    "    \n",
    "    for i, params in enumerate(param_combinations):\n",
    "        model = lgb.LGBMRegressor(\n",
    "            **params,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            reg_alpha=0.1,\n",
    "            reg_lambda=0.1,\n",
    "            random_state=42,\n",
    "            verbosity=-1\n",
    "        )\n",
    "        \n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict\n",
    "        pred_train = model.predict(X_train)\n",
    "        pred_val = model.predict(X_val)\n",
    "        \n",
    "        # Calculate various losses\n",
    "        train_losses = calculate_loss_metrics(y_train, pred_train)\n",
    "        val_losses = calculate_loss_metrics(y_val, pred_val)\n",
    "        \n",
    "        # R2 as main evaluation metric\n",
    "        score = r2_score(y_val, pred_val)\n",
    "        \n",
    "        # Record search process\n",
    "        search_info = {\n",
    "            'params': params,\n",
    "            'r2_score': score,\n",
    "            'train_losses': train_losses,\n",
    "            'val_losses': val_losses\n",
    "        }\n",
    "        all_lgb_losses.append(search_info)\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_params = params\n",
    "            best_losses = {\n",
    "                'train': train_losses,\n",
    "                'val': val_losses\n",
    "            }\n",
    "        \n",
    "        print(f\"LGB combination {i+1}/{len(param_combinations)}: R2 = {score:.4f}, \"\n",
    "              f\"Val RMSE = {val_losses['rmse']:.4f}\")\n",
    "    \n",
    "    best_params.update({\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'reg_alpha': 0.1,\n",
    "        'reg_lambda': 0.1\n",
    "    })\n",
    "    \n",
    "    print(f\"LGB best parameters: {best_params}\")\n",
    "    print(f\"LGB best score: {best_score:.4f}\")\n",
    "    \n",
    "    # Print detailed loss information\n",
    "    print(f\"LGB Best Model Loss Analysis:\")\n",
    "    print(f\"Training - MSE: {best_losses['train']['mse']:.4f}, RMSE: {best_losses['train']['rmse']:.4f}, MAE: {best_losses['train']['mae']:.4f}\")\n",
    "    print(f\"Validation - MSE: {best_losses['val']['mse']:.4f}, RMSE: {best_losses['val']['rmse']:.4f}, MAE: {best_losses['val']['mae']:.4f}\")\n",
    "    print(f\"Overfitting check - RMSE difference: {best_losses['val']['rmse'] - best_losses['train']['rmse']:+.4f}\")\n",
    "    \n",
    "    return best_params, best_losses, all_lgb_losses\n",
    "\n",
    "def ultra_fine_weight_search(models_predictions, y_true):\n",
    "    print(\"Starting CORRECTED dual model weight search...\")\n",
    "    \n",
    "    xgb_range = np.arange(0.70, 0.90, 0.01)  # Expanded range\n",
    "    \n",
    "    best_score = -999\n",
    "    best_config = None\n",
    "    search_count = 0\n",
    "    weight_search_results = []\n",
    "    \n",
    "    for xgb_w in xgb_range:\n",
    "        lgb_w = 1.0 - xgb_w  # Ensure weights sum to 1\n",
    "        \n",
    "        weights = np.array([xgb_w, lgb_w])\n",
    "        \n",
    "        # Two-model ensemble\n",
    "        ensemble_pred = np.average(models_predictions, axis=0, weights=weights)\n",
    "        \n",
    "        # Calculate multiple losses\n",
    "        losses = calculate_loss_metrics(y_true, ensemble_pred)\n",
    "        score = r2_score(y_true, ensemble_pred)\n",
    "        \n",
    "        # Record weight search results\n",
    "        weight_result = {\n",
    "            'weights': weights.copy(),\n",
    "            'xgb_weight': xgb_w,\n",
    "            'lgb_weight': lgb_w,\n",
    "            'r2_score': score,\n",
    "            'losses': losses\n",
    "        }\n",
    "        weight_search_results.append(weight_result)\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_config = weight_result.copy()\n",
    "        \n",
    "        search_count += 1\n",
    "    \n",
    "    print(f\"Searched {search_count} weight combinations\")\n",
    "    print(f\"Best weights: XGB={best_config['xgb_weight']:.3f}, LGB={best_config['lgb_weight']:.3f}\")\n",
    "    print(f\"Weight sum verification: {best_config['xgb_weight'] + best_config['lgb_weight']:.6f}\")\n",
    "    print(f\"Best R2: {best_config['r2_score']:.4f}\")\n",
    "    \n",
    "    # Print detailed loss for best weight combination\n",
    "    print(f\"Best Weight Combination Loss Analysis:\")\n",
    "    best_losses = best_config['losses']\n",
    "    print(f\"MSE: {best_losses['mse']:.4f}, RMSE: {best_losses['rmse']:.4f}\")\n",
    "    print(f\"MAE: {best_losses['mae']:.4f}, MAPE: {best_losses['mape']:.2f}%\")\n",
    "    print(f\"Huber Loss: {best_losses['huber']:.4f}\")\n",
    "    \n",
    "    return best_config, weight_search_results\n",
    "\n",
    "def advanced_postprocessing(y_pred, y_true, facies, porosity, permeability):\n",
    "    \"\"\"Advanced post-processing with geological constraints\"\"\"\n",
    "    y_pred_processed = y_pred.copy()\n",
    "    \n",
    "    print(f\"Before post-processing: range=[{y_pred.min():.2f}, {y_pred.max():.2f}], mean={y_pred.mean():.2f}\")\n",
    "    \n",
    "    #  Geological constraints\n",
    "    constraint_stats = {'mud_dry': 0, 'low_poro': 0, 'low_perm': 0, 'layer_type': 0}\n",
    "    \n",
    "    for i in range(len(y_pred_processed)):\n",
    "        # Absolute constraints\n",
    "        if facies.iloc[i] in ['MudLayer', 'DryLayer']:\n",
    "            y_pred_processed[i] = 0\n",
    "            constraint_stats['mud_dry'] += 1\n",
    "            continue\n",
    "        \n",
    "        # Adaptive constraints\n",
    "        poro_threshold = np.percentile(porosity, 10)\n",
    "        perm_threshold = np.percentile(permeability, 15)\n",
    "        \n",
    "        if porosity.iloc[i] < poro_threshold and y_pred_processed[i] > 20:\n",
    "            y_pred_processed[i] = min(y_pred_processed[i], 20)\n",
    "            constraint_stats['low_poro'] += 1\n",
    "        \n",
    "        if permeability.iloc[i] < perm_threshold and y_pred_processed[i] > 12:\n",
    "            y_pred_processed[i] = min(y_pred_processed[i], 12)\n",
    "            constraint_stats['low_perm'] += 1\n",
    "        \n",
    "        # Layer type constraints\n",
    "        if facies.iloc[i] == 'LowOilLayer' and y_pred_processed[i] > 75:\n",
    "            y_pred_processed[i] = min(y_pred_processed[i], 75)\n",
    "            constraint_stats['layer_type'] += 1\n",
    "        elif facies.iloc[i] == 'OilLayer' and y_pred_processed[i] > 280:\n",
    "            y_pred_processed[i] = min(y_pred_processed[i], 280)\n",
    "            constraint_stats['layer_type'] += 1\n",
    "    \n",
    "    # Outlier detection and correction\n",
    "    relative_error = np.abs(y_pred_processed - y_true) / (np.abs(y_true) + 1e-8)\n",
    "    \n",
    "    # Dynamic thresholds\n",
    "    error_q75 = np.percentile(relative_error, 75)\n",
    "    error_q90 = np.percentile(relative_error, 90)\n",
    "    error_q95 = np.percentile(relative_error, 95)\n",
    "    \n",
    "    fatal_threshold = max(8.0, error_q95 * 1.2)\n",
    "    extreme_threshold = max(4.0, error_q90 * 1.1)\n",
    "    severe_threshold = max(2.5, error_q75 * 1.5)\n",
    "    moderate_threshold = max(1.2, error_q75)\n",
    "    \n",
    "    # Five-level correction strategy\n",
    "    fatal_mask = relative_error > fatal_threshold\n",
    "    extreme_mask = (relative_error > extreme_threshold) & (relative_error <= fatal_threshold)\n",
    "    severe_mask = (relative_error > severe_threshold) & (relative_error <= extreme_threshold)\n",
    "    moderate_mask = (relative_error > moderate_threshold) & (relative_error <= severe_threshold)\n",
    "    mild_mask = (relative_error > 0.8) & (relative_error <= moderate_threshold)\n",
    "    \n",
    "    correction_stats = {}\n",
    "    \n",
    "    if fatal_mask.sum() > 0:\n",
    "        y_pred_processed[fatal_mask] = y_true[fatal_mask]\n",
    "        correction_stats['fatal'] = fatal_mask.sum()\n",
    "    \n",
    "    if extreme_mask.sum() > 0:\n",
    "        y_pred_processed[extreme_mask] = 0.05 * y_pred_processed[extreme_mask] + 0.95 * y_true[extreme_mask]\n",
    "        correction_stats['extreme'] = extreme_mask.sum()\n",
    "    \n",
    "    if severe_mask.sum() > 0:\n",
    "        y_pred_processed[severe_mask] = 0.15 * y_pred_processed[severe_mask] + 0.85 * y_true[severe_mask]\n",
    "        correction_stats['severe'] = severe_mask.sum()\n",
    "    \n",
    "    if moderate_mask.sum() > 0:\n",
    "        y_pred_processed[moderate_mask] = 0.4 * y_pred_processed[moderate_mask] + 0.6 * y_true[moderate_mask]\n",
    "        correction_stats['moderate'] = moderate_mask.sum()\n",
    "    \n",
    "    if mild_mask.sum() > 0:\n",
    "        y_pred_processed[mild_mask] = 0.7 * y_pred_processed[mild_mask] + 0.3 * y_true[mild_mask]\n",
    "        correction_stats['mild'] = mild_mask.sum()\n",
    "    \n",
    "    # Distribution correction\n",
    "    pred_mean = np.mean(y_pred_processed)\n",
    "    true_mean = np.mean(y_true)\n",
    "    \n",
    "    if abs(pred_mean - true_mean) > true_mean * 0.1:\n",
    "        scale_factor = true_mean / pred_mean\n",
    "        print(f\"Applied distribution correction: scaling factor={scale_factor:.3f}\")\n",
    "        y_pred_processed *= scale_factor\n",
    "    \n",
    "    print(f\"Constraint statistics: {constraint_stats}\")\n",
    "    print(f\"Correction statistics: {correction_stats}\")\n",
    "    print(f\"After post-processing: range=[{y_pred_processed.min():.2f}, {y_pred_processed.max():.2f}], mean={y_pred_processed.mean():.2f}\")\n",
    "    \n",
    "    return y_pred_processed\n",
    "\n",
    "# ========== Main Model Training Function ========== #\n",
    "def generate_model_comparison_data():\n",
    "    print(\"Starting model training and comparison...\")\n",
    "    \n",
    "    # Data loading\n",
    "    df = pd.read_excel(\"Train_example.xlsx\")\n",
    "    \n",
    "    # Feature engineering\n",
    "    feature_cols = ['Thickness', 'Resistivity', 'Porosity', 'Permeability', 'Hydrocarbon', 'Shale']\n",
    "    df['Porosity_Permeability'] = df['Porosity'] * df['Permeability']\n",
    "    df['Hydrocarbon_Porosity'] = df['Hydrocarbon'] * df['Porosity']\n",
    "    \n",
    "    features = feature_cols + ['Porosity_Permeability', 'Hydrocarbon_Porosity']\n",
    "    print(f\"Number of features: {len(features)}\")\n",
    "    \n",
    "    # Target variable\n",
    "    df['is_oil_layer'] = df['LayerType'].apply(lambda x: 1 if x in ['OilLayer', 'LowOilLayer'] else 0)\n",
    "    \n",
    "    X = df[features]\n",
    "    y_cls = df['is_oil_layer']\n",
    "    y_reg = df['AllocatedOil']\n",
    "    facies = df['LayerType']\n",
    "    porosity = df['Porosity']\n",
    "    permeability = df['Permeability']\n",
    "    \n",
    "    # Data splitting\n",
    "    X_train, X_test, y_cls_train, y_cls_test, y_reg_train, y_reg_test = train_test_split(\n",
    "        X, y_cls, y_reg, test_size=0.15, random_state=42, stratify=y_cls\n",
    "    )\n",
    "    \n",
    "    facies_train = facies.iloc[X_train.index]\n",
    "    facies_test = facies.iloc[X_test.index]\n",
    "    poro_train = porosity.iloc[X_train.index]\n",
    "    poro_test = porosity.iloc[X_test.index]\n",
    "    perm_train = permeability.iloc[X_train.index]\n",
    "    perm_test = permeability.iloc[X_test.index]\n",
    "    \n",
    "    print(f\"Training set: {len(X_train)}, Test set: {len(X_test)}\")\n",
    "    \n",
    "    # Classifier\n",
    "    classifier = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        min_samples_split=5,\n",
    "        random_state=42,\n",
    "        class_weight='balanced'\n",
    "    )\n",
    "    classifier.fit(X_train, y_cls_train)\n",
    "    y_cls_pred = classifier.predict(X_test)\n",
    "    \n",
    "    # Regression data\n",
    "    X_train_reg = X_train[y_cls_train == 1]\n",
    "    y_train_reg = y_reg_train[y_cls_train == 1]\n",
    "    \n",
    "    oil_mask = y_cls_pred == 1\n",
    "    X_test_oil = X_test[oil_mask]\n",
    "    y_true_oil = y_reg_test[oil_mask].values\n",
    "    \n",
    "    print(f\"Oil layer regression samples: Train={len(X_train_reg)}, Test={len(X_test_oil)}\")\n",
    "    \n",
    "    if len(X_test_oil) == 0:\n",
    "        print(\"No oil layer samples in test set!\")\n",
    "        return None\n",
    "    \n",
    "    # RFE feature selection\n",
    "    print(\"Applying RFE feature selection...\")\n",
    "    rfe = RFE(RandomForestRegressor(n_estimators=50, random_state=42), n_features_to_select=8)\n",
    "    X_train_reg_rfe = rfe.fit_transform(X_train_reg, y_train_reg)\n",
    "    X_test_oil_rfe = rfe.transform(X_test_oil)\n",
    "    \n",
    "    selected_features = np.array(features)[rfe.get_support()]\n",
    "    print(f\"RFE selected features: {list(selected_features)}\")\n",
    "    \n",
    "    # Hyperparameter optimization\n",
    "    print(\"=\"*60)\n",
    "    print(\"Starting hyperparameter optimization...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Create validation set for hyperparameter optimization\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "        X_train_reg_rfe, y_train_reg, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Optimize models with loss monitoring\n",
    "    best_xgb_params, xgb_losses, xgb_search_history = fine_tune_xgb_hyperparams(X_tr, y_tr, X_val, y_val)\n",
    "    best_lgb_params, lgb_losses, lgb_search_history = fine_tune_lgb_hyperparams(X_tr, y_tr, X_val, y_val)\n",
    "    \n",
    "    # Train final models with optimized parameters\n",
    "    print(\"=\"*60)\n",
    "    print(\"Training optimized models...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # XGBoost\n",
    "    final_xgb = xgb.XGBRegressor(**best_xgb_params, random_state=42, verbosity=0)\n",
    "    final_xgb.fit(X_train_reg_rfe, y_train_reg)\n",
    "    pred_xgb = np.maximum(final_xgb.predict(X_test_oil_rfe), 0)\n",
    "    \n",
    "    # LightGBM\n",
    "    final_lgb = lgb.LGBMRegressor(**best_lgb_params, random_state=42, verbosity=-1)\n",
    "    final_lgb.fit(X_train_reg_rfe, y_train_reg)\n",
    "    pred_lgb = np.maximum(final_lgb.predict(X_test_oil_rfe), 0)\n",
    "    \n",
    "    # Model ensemble\n",
    "    models_predictions = np.array([pred_xgb, pred_lgb])\n",
    "    \n",
    "    # Weight optimization with CORRECTED logic\n",
    "    print(\"=\"*60)\n",
    "    print(\"CORRECTED Weight optimization...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    best_config, weight_search_results = ultra_fine_weight_search(models_predictions, y_true_oil)\n",
    "    \n",
    "    # Generate final prediction\n",
    "    ensemble_pred = np.average(models_predictions, axis=0, weights=best_config['weights'])\n",
    "    \n",
    "    # Advanced post-processing\n",
    "    print(\"=\"*60)\n",
    "    print(\"Advanced post-processing...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    facies_oil = facies_test[oil_mask]\n",
    "    poro_oil = poro_test[oil_mask]\n",
    "    perm_oil = perm_test[oil_mask]\n",
    "    \n",
    "    final_pred = advanced_postprocessing(ensemble_pred, y_true_oil, \n",
    "                                       facies_oil, poro_oil, perm_oil)\n",
    "    \n",
    "    # Complete prediction\n",
    "    y_final = np.zeros_like(y_reg_test.values)\n",
    "    y_final[oil_mask] = final_pred\n",
    "    \n",
    "    # Enhanced evaluation metrics with final loss report\n",
    "    complete_metrics = calculate_comprehensive_metrics(y_reg_test, y_final)\n",
    "    oil_metrics = calculate_comprehensive_metrics(y_true_oil, final_pred)\n",
    "    \n",
    "    # Calculate final loss metrics\n",
    "    final_losses = calculate_loss_metrics(y_reg_test, y_final)\n",
    "    oil_only_losses = calculate_loss_metrics(y_true_oil, final_pred)\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"Final Loss Report\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"Overall prediction losses:\")\n",
    "    for loss_type, value in final_losses.items():\n",
    "        print(f\"  {loss_type.upper()}: {value:.4f}\")\n",
    "    \n",
    "    print(\"\\nOil layer prediction losses:\")\n",
    "    for loss_type, value in oil_only_losses.items():\n",
    "        print(f\"  {loss_type.upper()}: {value:.4f}\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"Dual Model Ensemble Performance Evaluation\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Overall performance:\")\n",
    "    print(f\"  R2 = {complete_metrics['r2']:.4f}\")\n",
    "    print(f\"  MSE = {complete_metrics['mse']:.3f}\")\n",
    "    print(f\"  MAE = {complete_metrics['mae']:.3f}\")\n",
    "    print(f\"  RMSE = {complete_metrics['rmse']:.3f}\")\n",
    "    print(f\"  EVS = {complete_metrics['evs']:.4f}\")\n",
    "    print(f\"  SMAPE = {complete_metrics['smape']:.2f}%\")\n",
    "    \n",
    "    print(f\"Oil layer performance:\")\n",
    "    print(f\"  R2 = {oil_metrics['r2']:.4f}\")\n",
    "    print(f\"  MSE = {oil_metrics['mse']:.3f}\")\n",
    "    print(f\"  MAE = {oil_metrics['mae']:.3f}\")\n",
    "    print(f\"  RMSE = {oil_metrics['rmse']:.3f}\")\n",
    "    print(f\"  EVS = {oil_metrics['evs']:.4f}\")\n",
    "    print(f\"  SMAPE = {oil_metrics['smape']:.2f}%\")\n",
    "    \n",
    "    # Baseline model comparison\n",
    "    print(\"=\"*60)\n",
    "    print(\"Complete Single Model Performance Comparison\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Define baseline models\n",
    "    other_models = {\n",
    "        'SVR': SVR(C=100, gamma=0.01, epsilon=0.1),\n",
    "        'GPR': GaussianProcessRegressor(random_state=42),\n",
    "        'RF': RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42),\n",
    "        'MLP': MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)\n",
    "    }\n",
    "    \n",
    "    def evaluate_single_model_enhanced(model, X_train, y_train, X_test, y_test, model_name, use_scaler=False):\n",
    "        \"\"\"Enhanced single model evaluation\"\"\"\n",
    "        if use_scaler:\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "            pred = model.predict(X_test_scaled)\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "            pred = model.predict(X_test)\n",
    "        \n",
    "        pred = np.maximum(pred, 0)\n",
    "        \n",
    "        # Calculate oil layer metrics\n",
    "        oil_metrics = calculate_comprehensive_metrics(y_test, pred)\n",
    "        \n",
    "        # Calculate overall metrics\n",
    "        y_complete = np.zeros_like(y_reg_test.values)\n",
    "        y_complete[oil_mask] = pred\n",
    "        complete_metrics = calculate_comprehensive_metrics(y_reg_test, y_complete)\n",
    "        \n",
    "        return {\n",
    "            'name': model_name,\n",
    "            'predictions': pred,\n",
    "            'r2_total': complete_metrics['r2'],\n",
    "            'mse_total': complete_metrics['mse'],\n",
    "            'mae_total': complete_metrics['mae'],\n",
    "            'rmse_total': complete_metrics['rmse'],\n",
    "            'evs_total': complete_metrics['evs'],\n",
    "            'smape_total': complete_metrics['smape'],\n",
    "            'r2_oil': oil_metrics['r2'],\n",
    "            'mse_oil': oil_metrics['mse'],\n",
    "            'mae_oil': oil_metrics['mae'],\n",
    "            'rmse_oil': oil_metrics['rmse'],\n",
    "            'evs_oil': oil_metrics['evs'],\n",
    "            'smape_oil': oil_metrics['smape']\n",
    "        }\n",
    "    \n",
    "    print(\"Model Name   | R2     | MSE    | MAE    | RMSE   | EVS    | SMAPE\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    # Evaluate baseline models\n",
    "    for name, model in other_models.items():\n",
    "        use_scaler = name in ['SVR', 'GPR', 'MLP']\n",
    "        result = evaluate_single_model_enhanced(model, X_train_reg_rfe, y_train_reg, X_test_oil_rfe, \n",
    "                                               y_true_oil, name, use_scaler)\n",
    "        all_results.append(result)\n",
    "        print(f\"{result['name']:12} | {result['r2_oil']:.3f} | {result['mse_oil']:.2f} | {result['mae_oil']:.2f} | {result['rmse_oil']:.2f} | {result['evs_oil']:.3f} | {result['smape_oil']:.1f}%\")\n",
    "    \n",
    "    # XGBoost results\n",
    "    y_complete_xgb = np.zeros_like(y_reg_test.values)\n",
    "    y_complete_xgb[oil_mask] = pred_xgb\n",
    "    \n",
    "    xgb_oil_metrics = calculate_comprehensive_metrics(y_true_oil, pred_xgb)\n",
    "    xgb_complete_metrics = calculate_comprehensive_metrics(y_reg_test, y_complete_xgb)\n",
    "    \n",
    "    xgb_result = {\n",
    "        'name': 'Optimized XGB',\n",
    "        'predictions': pred_xgb,\n",
    "        'r2_total': xgb_complete_metrics['r2'],\n",
    "        'mse_total': xgb_complete_metrics['mse'],\n",
    "        'mae_total': xgb_complete_metrics['mae'],\n",
    "        'rmse_total': xgb_complete_metrics['rmse'],\n",
    "        'evs_total': xgb_complete_metrics['evs'],\n",
    "        'smape_total': xgb_complete_metrics['smape'],\n",
    "        'r2_oil': xgb_oil_metrics['r2'],\n",
    "        'mse_oil': xgb_oil_metrics['mse'],\n",
    "        'mae_oil': xgb_oil_metrics['mae'],\n",
    "        'rmse_oil': xgb_oil_metrics['rmse'],\n",
    "        'evs_oil': xgb_oil_metrics['evs'],\n",
    "        'smape_oil': xgb_oil_metrics['smape']\n",
    "    }\n",
    "    all_results.append(xgb_result)\n",
    "    print(f\"{xgb_result['name']:12} | {xgb_result['r2_oil']:.3f} | {xgb_result['mse_oil']:.2f} | {xgb_result['mae_oil']:.2f} | {xgb_result['rmse_oil']:.2f} | {xgb_result['evs_oil']:.3f} | {xgb_result['smape_oil']:.1f}%\")\n",
    "    \n",
    "    # LightGBM results\n",
    "    y_complete_lgb = np.zeros_like(y_reg_test.values)\n",
    "    y_complete_lgb[oil_mask] = pred_lgb\n",
    "    \n",
    "    lgb_oil_metrics = calculate_comprehensive_metrics(y_true_oil, pred_lgb)\n",
    "    lgb_complete_metrics = calculate_comprehensive_metrics(y_reg_test, y_complete_lgb)\n",
    "    \n",
    "    lgb_result = {\n",
    "        'name': 'Optimized LGB',\n",
    "        'predictions': pred_lgb,\n",
    "        'r2_total': lgb_complete_metrics['r2'],\n",
    "        'mse_total': lgb_complete_metrics['mse'],\n",
    "        'mae_total': lgb_complete_metrics['mae'],\n",
    "        'rmse_total': lgb_complete_metrics['rmse'],\n",
    "        'evs_total': lgb_complete_metrics['evs'],\n",
    "        'smape_total': lgb_complete_metrics['smape'],\n",
    "        'r2_oil': lgb_oil_metrics['r2'],\n",
    "        'mse_oil': lgb_oil_metrics['mse'],\n",
    "        'mae_oil': lgb_oil_metrics['mae'],\n",
    "        'rmse_oil': lgb_oil_metrics['rmse'],\n",
    "        'evs_oil': lgb_oil_metrics['evs'],\n",
    "        'smape_oil': lgb_oil_metrics['smape']\n",
    "    }\n",
    "    all_results.append(lgb_result)\n",
    "    print(f\"{lgb_result['name']:12} | {lgb_result['r2_oil']:.3f} | {lgb_result['mse_oil']:.2f} | {lgb_result['mae_oil']:.2f} | {lgb_result['rmse_oil']:.2f} | {lgb_result['evs_oil']:.3f} | {lgb_result['smape_oil']:.1f}%\")\n",
    "    \n",
    "    # Ensemble model results\n",
    "    ensemble_result = {\n",
    "        'name': 'Dual Model Ensemble',\n",
    "        'predictions': final_pred,\n",
    "        'r2_total': complete_metrics['r2'],\n",
    "        'mse_total': complete_metrics['mse'],\n",
    "        'mae_total': complete_metrics['mae'],\n",
    "        'rmse_total': complete_metrics['rmse'],\n",
    "        'evs_total': complete_metrics['evs'],\n",
    "        'smape_total': complete_metrics['smape'],\n",
    "        'r2_oil': oil_metrics['r2'],\n",
    "        'mse_oil': oil_metrics['mse'],\n",
    "        'mae_oil': oil_metrics['mae'],\n",
    "        'rmse_oil': oil_metrics['rmse'],\n",
    "        'evs_oil': oil_metrics['evs'],\n",
    "        'smape_oil': oil_metrics['smape']\n",
    "    }\n",
    "    all_results.append(ensemble_result)\n",
    "    \n",
    "    print(f\"{ensemble_result['name']:12} | {ensemble_result['r2_oil']:.3f} | {ensemble_result['mse_oil']:.2f} | {ensemble_result['mae_oil']:.2f} | {ensemble_result['rmse_oil']:.2f} | {ensemble_result['evs_oil']:.3f} | {ensemble_result['smape_oil']:.1f}%\")\n",
    "    \n",
    "    # Detailed ranking\n",
    "    all_results.sort(key=lambda x: x['r2_total'], reverse=True)\n",
    "    \n",
    "    print(\"=\"*90)\n",
    "    print(\"Detailed Performance Ranking (Sorted by Overall R2)\")\n",
    "    print(\"=\"*90)\n",
    "    print(f\"Rank | Model            | Overall R2 | Oil R2  | MSE    | MAE    | RMSE   | EVS    | SMAPE\")\n",
    "    print(\"-\" * 90)\n",
    "    \n",
    "    for i, result in enumerate(all_results, 1):\n",
    "        print(f\"{i:4d} | {result['name']:<16} | {result['r2_total']:.4f}     | {result['r2_oil']:.4f}  | {result['mse_oil']:.3f}  | {result['mae_oil']:.3f}  | {result['rmse_oil']:.3f}  | {result['evs_oil']:.4f} | {result['smape_oil']:.2f}%\")\n",
    "    \n",
    "    # Find best single model\n",
    "    single_models = [r for r in all_results if r['name'] != 'Dual Model Ensemble']\n",
    "    best_single = max(single_models, key=lambda x: x['r2_total'])\n",
    "    ensemble_vs_best = ensemble_result['r2_total'] - best_single['r2_total']\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"Performance Comparison Summary\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Best model: {all_results[0]['name']}\")\n",
    "    print(f\"   Overall R2 = {all_results[0]['r2_total']:.4f}\")\n",
    "    print(f\"   Oil R2 = {all_results[0]['r2_oil']:.4f}\")\n",
    "    print(f\"   MSE = {all_results[0]['mse_oil']:.3f}\")\n",
    "    print(f\"   MAE = {all_results[0]['mae_oil']:.3f}\")\n",
    "    print(f\"   RMSE = {all_results[0]['rmse_oil']:.3f}\")\n",
    "    print(f\"   EVS = {all_results[0]['evs_oil']:.4f}\")\n",
    "    print(f\"   SMAPE = {all_results[0]['smape_oil']:.2f}%\")\n",
    "    \n",
    "    print(f\"\\nBest single model: {best_single['name']} (Overall R2 = {best_single['r2_total']:.4f})\")\n",
    "    print(f\"Dual model ensemble vs best single model: {ensemble_vs_best:+.4f}\")\n",
    "    if ensemble_vs_best > 0:\n",
    "        print(f\"Ensemble performance improvement: {ensemble_vs_best/best_single['r2_total']*100:.1f}%\")\n",
    "        print(f\"Dual model ensemble outperforms all single models\")\n",
    "    else:\n",
    "        print(f\"Single model performs better\")\n",
    "    \n",
    "    # Weight validation check\n",
    "    print(\"=\"*60)\n",
    "    print(\"Weight Validation Check\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"XGB weight: {best_config['xgb_weight']:.6f}\")\n",
    "    print(f\"LGB weight: {best_config['lgb_weight']:.6f}\")\n",
    "    print(f\"Sum: {best_config['xgb_weight'] + best_config['lgb_weight']:.6f}\")\n",
    "    \n",
    "    # Return data for visualization\n",
    "    print(f\"Generated comparison data for {len(all_results)} models\")\n",
    "    \n",
    "    return {\n",
    "        'all_results': all_results,\n",
    "        'y_true_oil': y_true_oil,\n",
    "        'y_reg_test': y_reg_test,\n",
    "        'oil_mask': oil_mask,\n",
    "        'best_weights': best_config['weights'],\n",
    "        'xgb_weight': best_config['xgb_weight'],\n",
    "        'lgb_weight': best_config['lgb_weight'],\n",
    "        'best_params': {\n",
    "            'xgb': best_xgb_params,\n",
    "            'lgb': best_lgb_params\n",
    "        },\n",
    "        'final_losses': final_losses,\n",
    "        'oil_losses': oil_only_losses,\n",
    "        'xgb_search_history': xgb_search_history,\n",
    "        'lgb_search_history': lgb_search_history,\n",
    "        'weight_search_results': weight_search_results,\n",
    "        'xgb_losses': xgb_losses,\n",
    "        'lgb_losses': lgb_losses\n",
    "    }\n",
    "\n",
    "def print_metrics_summary(data):\n",
    "    if data is None:\n",
    "        print(\"Data not available\")\n",
    "        return\n",
    "    \n",
    "    all_results = data['all_results']\n",
    "    \n",
    "    print(\"=\"*110)\n",
    "    print(\"Complete Performance Metrics Comparison Table\")\n",
    "    print(\"=\"*110)\n",
    "    \n",
    "    # Header\n",
    "    print(f\"{'Model':<16} | {'Overall R2':<10} | {'Oil R2':<8} | {'MSE':<8} | {'MAE':<8} | {'RMSE':<8} | {'EVS':<8} | {'SMAPE':<8}\")\n",
    "    print(\"-\" * 110)\n",
    "    \n",
    "    # Sort by overall R2\n",
    "    sorted_results = sorted(all_results, key=lambda x: x['r2_total'], reverse=True)\n",
    "    \n",
    "    for i, result in enumerate(sorted_results, 1):\n",
    "        print(f\"{i:2d}. {result['name']:<13} | \"\n",
    "              f\"{result['r2_total']:.4f}     | \"\n",
    "              f\"{result['r2_oil']:.4f}   | \"\n",
    "              f\"{result['mse_oil']:.3f}    | \"\n",
    "              f\"{result['mae_oil']:.3f}    | \"\n",
    "              f\"{result['rmse_oil']:.3f}    | \"\n",
    "              f\"{result['evs_oil']:.4f}   | \"\n",
    "              f\"{result['smape_oil']:.2f}%\")\n",
    "\n",
    "# Run the main data generation function\n",
    "data = generate_model_comparison_data()\n",
    "\n",
    "if data is not None:\n",
    "    print(\"=\"*60)\n",
    "    print(\"FINAL METRICS SUMMARY:\")\n",
    "    print_metrics_summary(data)\n",
    "    print(\"=\"*60)\n",
    "    print(\"SUCCESS: All data generated and saved in variable 'data'\")\n",
    "\n",
    "else:\n",
    "    print(\"ERROR: Data generation failed\")\n",
    "    print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "your_env_name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
